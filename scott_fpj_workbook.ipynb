{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Criteo Labs Display Advertising Challenge\n",
    "__`MIDS w261: Machine Learning at Scale | UC Berkeley School of Information | Spring 2019`__\n",
    "\n",
    "__`Team: Chi Iong Ansjory, Catherine Cao, Scott Xu`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Content:\n",
    "- [0. Background](#background)\n",
    "- [1. Question Formulation](#question_formulation)\n",
    "- [2. Algorithm Explanation](#algorithm_explanation)\n",
    "- [3. EDA & Discussion of Challenges](#eda_challenges)\n",
    "- [4. Algorithm Implementation](#algorithm_implementation)\n",
    "- [5. Application of Course Concepts](#course_concepts_application)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='background'></a>\n",
    "# 0. Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criteo Labs is a leading global technology company that specializes in performance display advertising, working with over 4,000 e-commerce companies around the world. Their technology takes an algorithmic approach to determining what user they show an advertisement to, when, and for what products. For billions of unique advertisements that are created and displayed at lightning fast speeds every day.\n",
    "\n",
    "Display advertising is a billion dollar effort and one of the central uses of Machine Learning on the Internet. However, its data and methods are usually kept confidential. Through the Kaggle research competition, Criteo Labs is sharing a weekâ€™s worth of data for participants to develop models predicting advertisement click-through rate (CTR). Given a user and the page being visited, what is the probability that the user will click on a given advertisement?\n",
    "\n",
    "Source: https://www.kaggle.com/c/criteo-display-ad-challenge\n",
    "\n",
    "For the dataset, the smaller version is no longer available from Kaggle. The full-size version needs to be used instead from Criteo Labs.\n",
    "\n",
    "Source: https://www.kaggle.com/c/criteo-display-ad-challenge/data (smaller version - obsoleted); http://labs.criteo.com/2014/02/kaggle-display-advertising-challenge-dataset/ (full-size version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import udf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store path to notebook\n",
    "PWD = !pwd\n",
    "PWD = PWD[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='question_formulation'></a>\n",
    "# 1. Question Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this analysis is to benchmark the most accurate ML algorithms for CTR estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='algorithm_explanation'></a>\n",
    "# 2. Algorithm Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is an ensemble method for classification and regression. The algorithm creates multiple trees. Each tree will give a prediction on its own. And final prediction is the most common from all the trees(classification) or the average (regression). In order to remove the correlation between each tree, it use bagging to sample 1) the training data 2) the features. So that each tree will have slightly different input. Overall random forest helps improve the model performance and avoid the overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda_challenges'></a>\n",
    "# 3. EDA & Discussion of Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main challenges are the dataset given for this analysis has no column labels. We can't leverage any of our pre-existing knowledge about how online ads are served and CTR is computed in understanding the data. This means we have to put in extra effort in analyzing the data so we can understand the relationships between different features in the dataset and process them appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "app_name = \"final\"\n",
    "master = \"local[*]\"\n",
    "MAX_MEMORY = \"4g\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .config(\"spark.executor.memory\", MAX_MEMORY) \\\n",
    "        .config(\"spark.driver.memory\", MAX_MEMORY) \\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"./data/train.txt\")\n",
    "\n",
    "#rdd_sample = rdd.sample(fraction = 0.001, withReplacement= False).cache()\n",
    "\n",
    "numeric_features = ['I'+str(i) for i in [x for x in range(1, 14) if x !=12] ]\n",
    "categorical_features = ['C'+str(i) for i in [x for x in range(1, 27) if x !=22]]\n",
    "header = ['target'] + numeric_features + categorical_features\n",
    "\n",
    "df = rdd.map(lambda x: x.split(\"\\t\")).toDF(header).cache()\n",
    "\n",
    "for var in ['target'] + numeric_features:\n",
    "    df =df.withColumn(var, df[var].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45840617"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6042135"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_test = sc.textFile(\"./data/test.txt\")\n",
    "rdd_test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='algorithm_implementation'></a>\n",
    "# 4. Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('', None, categorical_features)\n",
    "with open(\"imputation_int.json\") as json_file:  \n",
    "    impute = json.load(json_file)\n",
    "    del impute['C22']\n",
    "    del impute['I12']\n",
    "df_impute = df.replace('', None, categorical_features)\n",
    "df_impute = df_impute.fillna(impute)\n",
    "\n",
    "hex_string=udf(lambda x:int(x,16),IntegerType())\n",
    "\n",
    "for col in categorical_features:\n",
    "    df_impute = df_impute.withColumn(col,hex_string(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    stages = []\n",
    "#     categorical_features_index=[]\n",
    "#    ['C1','C2','C5','C6','C8','C9','C11','C13','C14','C15','C17','C18','C19','C20','C22','C23','C25']\n",
    "#     for categoricalCol in categorical_features:\n",
    "#         stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "#         encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "#         #encoder = VectorIndexer(inputCol=[stringIndexer.getOutputCol()], outputCol=[categoricalCol + \"classVec\"])\n",
    "#         categorical_features_index += [categoricalCol + 'Index']\n",
    "#         stages += [stringIndexer,encoder]\n",
    "    #print(categorical_features_index)\n",
    "\n",
    "    vector_assembler = VectorAssembler( \\\n",
    "        inputCols= numeric_features+ categorical_features, \\\n",
    "        outputCol=\"features\")\n",
    "\n",
    "    stages += [vector_assembler] \n",
    "    pipeline = Pipeline(stages = stages)\n",
    "\n",
    "    pipelineModel = pipeline.fit(df)\n",
    "    df_temp = pipelineModel.transform(df)\n",
    "    \n",
    "    return df_temp, pipelineModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0.02083730697631836 seconds\n",
      "root\n",
      " |-- target: integer (nullable = true)\n",
      " |-- I1: integer (nullable = false)\n",
      " |-- I2: integer (nullable = false)\n",
      " |-- I3: integer (nullable = false)\n",
      " |-- I4: integer (nullable = false)\n",
      " |-- I5: integer (nullable = false)\n",
      " |-- I6: integer (nullable = false)\n",
      " |-- I7: integer (nullable = false)\n",
      " |-- I8: integer (nullable = false)\n",
      " |-- I9: integer (nullable = false)\n",
      " |-- I10: integer (nullable = false)\n",
      " |-- I11: integer (nullable = false)\n",
      " |-- I13: integer (nullable = false)\n",
      " |-- C1: integer (nullable = true)\n",
      " |-- C2: integer (nullable = true)\n",
      " |-- C3: integer (nullable = true)\n",
      " |-- C4: integer (nullable = true)\n",
      " |-- C5: integer (nullable = true)\n",
      " |-- C6: integer (nullable = true)\n",
      " |-- C7: integer (nullable = true)\n",
      " |-- C8: integer (nullable = true)\n",
      " |-- C9: integer (nullable = true)\n",
      " |-- C10: integer (nullable = true)\n",
      " |-- C11: integer (nullable = true)\n",
      " |-- C12: integer (nullable = true)\n",
      " |-- C13: integer (nullable = true)\n",
      " |-- C14: integer (nullable = true)\n",
      " |-- C15: integer (nullable = true)\n",
      " |-- C16: integer (nullable = true)\n",
      " |-- C17: integer (nullable = true)\n",
      " |-- C18: integer (nullable = true)\n",
      " |-- C19: integer (nullable = true)\n",
      " |-- C20: integer (nullable = true)\n",
      " |-- C21: integer (nullable = true)\n",
      " |-- C23: integer (nullable = true)\n",
      " |-- C24: integer (nullable = true)\n",
      " |-- C25: integer (nullable = true)\n",
      " |-- C26: integer (nullable = true)\n",
      " |-- _39: string (nullable = true)\n",
      " |-- _40: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df_temp, pipelineModel = preprocess(df_impute)\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "df_temp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC: 0.7083715760474067\n",
      "Wall time: 3488.9581015110016 seconds\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = df_temp.randomSplit([0.7, 0.3])\n",
    "start = time.time()\n",
    "rf = RandomForestClassifier(labelCol=\"target\",\\\n",
    "featuresCol=\"features\", numTrees=100)\n",
    "model = rf.fit(trainingData)\n",
    "\n",
    "predictions = model.transform(testData)\n",
    "evaluator = BinaryClassificationEvaluator(labelCol = \"target\")\n",
    "\n",
    "print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[target: int, I1: int, I2: int, I3: int, I4: int, I5: int, I6: int, I7: int, I8: int, I9: int, I10: int, I11: int, I12: int, I13: int, C1: string, C2: string, C3: string, C4: string, C5: string, C6: string, C7: string, C8: string, C9: string, C10: string, C11: string, C12: string, C13: string, C14: string, C15: string, C16: string, C17: string, C18: string, C19: string, C20: string, C21: string, C22: string, C23: string, C24: string, C25: string, C26: string, C6Index: double, C6classVec: vector, C9Index: double, C9classVec: vector, C14Index: double, C14classVec: vector, C17Index: double, C17classVec: vector, C20Index: double, C20classVec: vector, C23Index: double, C23classVec: vector, C25Index: double, C25classVec: vector, features: vector, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(avg(logloss)=0.5186227341338779)]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "import math\n",
    "\n",
    "def logloss(prob, actual):\n",
    "    if actual == 1:\n",
    "        return -math.log(prob)\n",
    "    else:\n",
    "        return -math.log(1-prob)\n",
    "\n",
    "udf_logloss = udf(logloss, FloatType())\n",
    "\n",
    "firstelement=udf(lambda v:float(v[1]),FloatType())\n",
    "logloss = predictions.select(firstelement('probability').alias('probability'), 'target').withColumn(\"logloss\", udf_logloss(\"probability\",\"target\"))\\\n",
    "       .groupby().avg('logloss').collect()\n",
    "print (logloss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_test = sc.textFile(\"./data/test.txt\")\n",
    "numeric_features = ['I'+str(i) for i in range(1, 14)]\n",
    "categorical_features = ['C'+str(i) for i in range(1, 27)]\n",
    "header_test = numeric_features + categorical_features\n",
    "df_test = rdd_test.map(lambda x: x.split(\"\\t\")).toDF(header_test).cache()\n",
    "\n",
    "for var in numeric_features:\n",
    "    df_test =df_test.withColumn(var, df_test[var].cast(IntegerType()))\n",
    "    \n",
    "df_test.replace('', None, categorical_features)\n",
    "with open(\"imputation_int.json\") as json_file:  \n",
    "    impute = json.load(json_file)\n",
    "df_impute_test=df_test.replace('', None, categorical_features)\n",
    "df_impute_test = df_impute_test.fillna(impute)\n",
    "\n",
    "hex_string=udf(lambda x:int(x,16),IntegerType())\n",
    "\n",
    "for col in categorical_features:\n",
    "    df_impute_test = df_impute_test.withColumn(col,hex_string(col))\n",
    "\n",
    "df_temp_test = pipelineModel.transform(df_impute_test)\n",
    "\n",
    "predictions_test = model.transform(df_temp_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predictions_test.select(firstelement('probability').alias('Predicted')).toPandas()\n",
    "submission = pd.read_csv('random_submission.csv')\n",
    "submission2 = pd.concat([submission['Id'], pred['Predicted']], axis=1)\n",
    "#submission2.rename(columns={'probability':'Predicted'}, inplace=True)\n",
    "submission2.to_csv('predictions_rf3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60000000</td>\n",
       "      <td>0.179017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60000001</td>\n",
       "      <td>0.272029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60000002</td>\n",
       "      <td>0.355309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60000003</td>\n",
       "      <td>0.183668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60000004</td>\n",
       "      <td>0.333123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id  Predicted\n",
       "0  60000000   0.179017\n",
       "1  60000001   0.272029\n",
       "2  60000002   0.355309\n",
       "3  60000003   0.183668\n",
       "4  60000004   0.333123"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----------+--------------------+\n",
      "|target|       rawPrediction|prediction|         probability|\n",
      "+------+--------------------+----------+--------------------+\n",
      "|     0|[85.9569560005486...|       0.0|[0.85956956000548...|\n",
      "|     0|[81.0723273102391...|       0.0|[0.81072327310239...|\n",
      "|     0|[76.8602831987373...|       0.0|[0.76860283198737...|\n",
      "|     0|[84.1087912534379...|       0.0|[0.84108791253437...|\n",
      "|     0|[79.3108344510999...|       0.0|[0.79310834451099...|\n",
      "|     0|[75.0067298049367...|       0.0|[0.75006729804936...|\n",
      "|     0|[81.5320252434899...|       0.0|[0.81532025243489...|\n",
      "|     0|[81.3178605316716...|       0.0|[0.81317860531671...|\n",
      "|     0|[78.7006942259489...|       0.0|[0.78700694225948...|\n",
      "|     0|[84.2800906835654...|       0.0|[0.84280090683565...|\n",
      "+------+--------------------+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('target', 'rawPrediction', 'prediction', 'probability').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='course_concepts_application'></a>\n",
    "# 5. Application of Course Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
